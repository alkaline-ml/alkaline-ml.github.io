{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem setup:\n",
    "\n",
    "The last step in most machine learning problems is to tune a model with a grid search. However, you have to be careful how you evaluate the results of the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=3, random_state=1, shuffle=True),\n",
       "          error_score='raise',\n",
       "          estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "             presort='auto', random_state=42, subsample=1.0, verbose=0,\n",
       "             warm_start=False),\n",
       "          fit_params={}, iid=True, n_iter=25, n_jobs=4,\n",
       "          param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x10388d9b0>, 'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x117542a20>, 'learning_rate': array([0.001  , 0.00147, 0.00195, 0.00242, 0.00289, 0.00337, 0.00384,\n",
       "       0.00432, 0.00479, 0.00526, 0.00574, 0.00621, 0.00668, 0.00716,\n",
       "       0.00763, 0.00811, 0.00858, 0.00905, 0.00953, 0.01   ]), 'min_samples_leaf': [1, 5, 10]},\n",
       "          pre_dispatch='2*n_jobs', random_state=12, refit=True,\n",
       "          return_train_score=True, scoring='neg_mean_squared_error',\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from scipy.stats import randint\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "X, y = load_boston(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Define (roughly) our hyper parameters\n",
    "hyper = {\n",
    "    'max_depth': randint(3, 10),\n",
    "    'n_estimators': randint(25, 250),\n",
    "    'learning_rate': np.linspace(0.001, 0.01, 20),\n",
    "    'min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "\n",
    "# Define our CV class (remember to always shuffle!)\n",
    "cv = KFold(shuffle=True, n_splits=3, random_state=1)\n",
    "\n",
    "# Define our estimator\n",
    "search = RandomizedSearchCV(GradientBoostingRegressor(random_state=42),\n",
    "                            scoring='neg_mean_squared_error', n_iter=25,\n",
    "                            param_distributions=hyper, cv=cv,\n",
    "                            random_state=12, n_jobs=4)\n",
    "\n",
    "# Fit the grid search\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to know if the model is good enough. __Does this model meet business requirements?__\n",
    "\n",
    "## Wrong approach:\n",
    "\n",
    "If you repeatedly expose your model to your test set, you risk \"p-hacking\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 12.394\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Evaluate:\n",
    "print(\"Test MSE: %.3f\" % mean_squared_error(y_test, search.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the wrong approach since you've now gained information that could cause model leakage. If you decide to make adjustments to your model to improve the test score, you're effectively fitting the test set indirectly.\n",
    "\n",
    "The more appropriate approach is to examine the CV scores of the model.\n",
    "\n",
    "## Better approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-9.779118</td>\n",
       "      <td>-36.088421</td>\n",
       "      <td>-11.244133</td>\n",
       "      <td>-19.012796</td>\n",
       "      <td>12.065257</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.539486</td>\n",
       "      <td>-2.213193</td>\n",
       "      <td>-3.721718</td>\n",
       "      <td>-3.158132</td>\n",
       "      <td>0.672302</td>\n",
       "      <td>0.166742</td>\n",
       "      <td>0.009509</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>228</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 7, 'min_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-13.972549</td>\n",
       "      <td>-38.821430</td>\n",
       "      <td>-15.160443</td>\n",
       "      <td>-22.628574</td>\n",
       "      <td>11.437726</td>\n",
       "      <td>2</td>\n",
       "      <td>-8.256319</td>\n",
       "      <td>-6.447233</td>\n",
       "      <td>-9.416248</td>\n",
       "      <td>-8.039934</td>\n",
       "      <td>1.221714</td>\n",
       "      <td>0.114991</td>\n",
       "      <td>0.002640</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.00905263</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "      <td>{'learning_rate': 0.009052631578947368, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-14.944225</td>\n",
       "      <td>-39.504609</td>\n",
       "      <td>-15.895012</td>\n",
       "      <td>-23.425511</td>\n",
       "      <td>11.353793</td>\n",
       "      <td>3</td>\n",
       "      <td>-9.331705</td>\n",
       "      <td>-7.419460</td>\n",
       "      <td>-10.591472</td>\n",
       "      <td>-9.114212</td>\n",
       "      <td>1.304069</td>\n",
       "      <td>0.164653</td>\n",
       "      <td>0.007149</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.00621053</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>228</td>\n",
       "      <td>{'learning_rate': 0.0062105263157894745, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-16.173797</td>\n",
       "      <td>-39.453283</td>\n",
       "      <td>-18.064387</td>\n",
       "      <td>-24.541685</td>\n",
       "      <td>10.551537</td>\n",
       "      <td>4</td>\n",
       "      <td>-13.251544</td>\n",
       "      <td>-10.359841</td>\n",
       "      <td>-14.557962</td>\n",
       "      <td>-12.723116</td>\n",
       "      <td>1.754134</td>\n",
       "      <td>0.090297</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.00715789</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>183</td>\n",
       "      <td>{'learning_rate': 0.007157894736842105, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-19.206718</td>\n",
       "      <td>-41.374121</td>\n",
       "      <td>-17.530125</td>\n",
       "      <td>-26.018966</td>\n",
       "      <td>10.857879</td>\n",
       "      <td>5</td>\n",
       "      <td>-15.349376</td>\n",
       "      <td>-11.007713</td>\n",
       "      <td>-15.804780</td>\n",
       "      <td>-14.053956</td>\n",
       "      <td>2.162028</td>\n",
       "      <td>0.082872</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.00857895</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>148</td>\n",
       "      <td>{'learning_rate': 0.008578947368421054, 'max_d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "14          -9.779118         -36.088421         -11.244133       -19.012796   \n",
       "2          -13.972549         -38.821430         -15.160443       -22.628574   \n",
       "13         -14.944225         -39.504609         -15.895012       -23.425511   \n",
       "9          -16.173797         -39.453283         -18.064387       -24.541685   \n",
       "8          -19.206718         -41.374121         -17.530125       -26.018966   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "14       12.065257                1           -3.539486           -2.213193   \n",
       "2        11.437726                2           -8.256319           -6.447233   \n",
       "13       11.353793                3           -9.331705           -7.419460   \n",
       "9        10.551537                4          -13.251544          -10.359841   \n",
       "8        10.857879                5          -15.349376          -11.007713   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  mean_fit_time  \\\n",
       "14           -3.721718         -3.158132         0.672302       0.166742   \n",
       "2            -9.416248         -8.039934         1.221714       0.114991   \n",
       "13          -10.591472         -9.114212         1.304069       0.164653   \n",
       "9           -14.557962        -12.723116         1.754134       0.090297   \n",
       "8           -15.804780        -14.053956         2.162028       0.082872   \n",
       "\n",
       "    std_fit_time  mean_score_time  std_score_time param_learning_rate  \\\n",
       "14      0.009509         0.001527        0.000196                0.01   \n",
       "2       0.002640         0.001153        0.000166          0.00905263   \n",
       "13      0.007149         0.001520        0.000124          0.00621053   \n",
       "9       0.003094         0.000796        0.000126          0.00715789   \n",
       "8       0.000505         0.000931        0.000122          0.00857895   \n",
       "\n",
       "   param_max_depth param_min_samples_leaf param_n_estimators  \\\n",
       "14               7                      5                228   \n",
       "2                7                      5                166   \n",
       "13               7                      5                228   \n",
       "9                4                      5                183   \n",
       "8                7                     10                148   \n",
       "\n",
       "                                               params  \n",
       "14  {'learning_rate': 0.01, 'max_depth': 7, 'min_s...  \n",
       "2   {'learning_rate': 0.009052631578947368, 'max_d...  \n",
       "13  {'learning_rate': 0.0062105263157894745, 'max_...  \n",
       "9   {'learning_rate': 0.007157894736842105, 'max_d...  \n",
       "8   {'learning_rate': 0.008578947368421054, 'max_d...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(search.cv_results_)\\\n",
    "  .sort_values('mean_test_score',\n",
    "               # descend since neg MSE\n",
    "               ascending=False)\\\n",
    "  .head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV outside scope of grid search:\n",
    "\n",
    "You typically don't go straight into a grid search. First, you try several models. Scikit allows us to fit a model in the context of cross validation and examine the fold scores. This\n",
    "is useful for determining whether a model will perform in the ballpark of business requirements before a lengthy tuning process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -7.62352454, -15.10931642, -16.47872053])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Set our CV seed\n",
    "cv = KFold(n_splits=3, random_state=0, shuffle=True)\n",
    "\n",
    "# Fit and score a model in CV:\n",
    "cross_val_score(GradientBoostingRegressor(random_state=42),\n",
    "                X_train, y_train, cv=cv, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
